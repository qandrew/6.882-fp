{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "path = '../RetweetDataAOAS/retweet_data/'\n",
    "root_tweet_names = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "num_root_tweets = len(root_tweet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produces a dictionary of dataframes for each tweetfile, with initial \n",
    "# preprocessing\n",
    "fields = ['RetweetCount', 'UserId', 'ScreenName', 'FollowerCount', \n",
    "          'DistanceFromRoot','Time', 'ParentScreenName', 'Text']\n",
    "tweet_dfs = []\n",
    "for i in range(num_root_tweets):\n",
    "    tweet_df = pd.read_csv(path+root_tweet_names[i], sep=\"\\t\", header=None, \n",
    "                         quoting=csv.QUOTE_NONE, names=fields, encoding = \"ISO-8859-1\")\n",
    "    \n",
    "    tweet_df['Time'] = pd.to_datetime(tweet_df['Time'])\n",
    "#     tweet_df[\"UserId\"] = pd.to_numeric(tweet_df[\"UserId\"], errors = 'ignore')\n",
    "    \n",
    "    screen_name_index = {}\n",
    "    for index, row in tweet_df.iterrows():\n",
    "        screen_name_index[row['ScreenName']] = index\n",
    "    tweet_df['ParentDfIndex'] = tweet_df['ParentScreenName'].map(screen_name_index)\n",
    "    \n",
    "    tweet_dfs.append(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dictionary of reaction times S_j^x keyed by user id\n",
    "# Also modify the df to include a ReactionTime column\n",
    "# S_j^x = T_j^x - T_P(j)^x is the time of the user's tweet minus its parent\n",
    "\n",
    "def generate_reaction_times(tweet_df):\n",
    "    reaction_times = {}\n",
    "    for index, row in tweet_df.iterrows():\n",
    "#         if index > 0: # ignore root tweet\n",
    "        reaction_time = row['Time'] - tweet_df.at[row['ParentDfIndex'],\n",
    "                                                  'Time']\n",
    "        reaction_times[row['UserId']] = reaction_time\n",
    "        tweet_df.loc[index,\"ReactionTime\"] = reaction_time\n",
    "    return reaction_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifies the dataframe to include M_j^x\n",
    "# M_j^x for tweet x and user j is the number of j's followers who retweet x\n",
    "\n",
    "def generate_number_of_follower_who_retweet(tweet_df):\n",
    "    number_of_follower_who_retweet = {}\n",
    "    \n",
    "    for index, row in tweet_df.iterrows():\n",
    "        parent_user_id = tweet_df.at[row['ParentDfIndex'], 'UserId']\n",
    "        if parent_user_id not in number_of_follower_who_retweet:\n",
    "            number_of_follower_who_retweet[parent_user_id] =1\n",
    "        else:\n",
    "            number_of_follower_who_retweet[parent_user_id] += 1\n",
    "    \n",
    "    # add to dataFrame\n",
    "#     for index, row in tweet_df.iterrows():\n",
    "#         if row['UserId'] in number_of_follower_who_retweet:\n",
    "#             count = number_of_follower_who_retweet[row['UserId']]\n",
    "#             tweet_df.loc[index,\"FollowersRetweeted\"] = count\n",
    "#         else: \n",
    "#             tweet_df.loc[index,\"FollowersRetweeted\"] = 0\n",
    "\n",
    "    return number_of_follower_who_retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_s_j_x = []\n",
    "for i in range(num_root_tweets):\n",
    "    s_j_x = sorted(generate_reaction_times(tweet_dfs[i]).values())\n",
    "    log_s_j_x.append([np.log(i.seconds) for i in s_j_x])\n",
    "fake_logs = [[1 for i in range(num_root_tweets)] for j in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11604"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of unique users\n",
    "\n",
    "t = tweet_dfs[0]['UserId']\n",
    "for i in range(1,len(tweet_dfs)):\n",
    "    t = pd.concat([t, tweet_dfs[i]['UserId']])\n",
    "t.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently working pymc3 model \n",
    "with pm.Model() as twitter_model:\n",
    "    # global model parameters\n",
    "    # Time-related hyperparameters\n",
    "    alpha = pm.Normal('alpha', mu=0, sd=100)\n",
    "    sigma_squared_delta = pm.InverseGamma('sigma_squared_delta', alpha=2, beta=2)\n",
    "    log_a_tau = pm.Normal('log_a_tau', mu=0, sd=10)\n",
    "    b_tau = pm.Gamma('b_tau', alpha=1, beta=.002)\n",
    "    \n",
    "    # Graph-related hyperparameters\n",
    "    # sigma_squared_b = pm.InverseGamma('sigma_squared_b', alpha=0.5, beta=0.5, testval=10000)\n",
    "    # beta_0 = pm.Normal('beta_0', mu=0, tau=1/sigma_squared_b)\n",
    "    # beta_F = pm.Normal('beta_F', mu=0, tau=1/sigma_squared_b)\n",
    "    # beta_d = pm.Normal('beta_d', mu=0, tau=1/sigma_squared_b)\n",
    "    \n",
    "    # log-normal model for reaction times, nonrecursive...\n",
    "    a_tau = pm.Deterministic('a_tau', pm.math.exp(log_a_tau))\n",
    "    for i in range(num_root_tweets):\n",
    "        t_x = pm.InverseGamma('tau_x_squared_' + str(i), alpha=a_tau, beta=b_tau)\n",
    "        a_x = pm.Normal('alpha_x_' + str(i), mu=alpha, tau=1/sigma_squared_delta)        \n",
    "        l_x = pm.Normal('log_s_j_x_' + str(i), mu=a_x, tau=t_x**0.5, observed=log_s_j_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    }
   ],
   "source": [
    "# Run and fit our model\n",
    "with twitter_model:\n",
    "    trace = pm.sample(1000, tune=1000, cores=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
