{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import scipy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "path = '../RetweetDataAOAS/retweet_data/'\n",
    "root_tweet_names = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "num_root_tweets = len(root_tweet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produces a dictionary of dataframes for each tweetfile, with initial \n",
    "# preprocessing\n",
    "fields = ['RetweetCount', 'UserId', 'ScreenName', 'FollowerCount', \n",
    "          'DistanceFromRoot','Time', 'ParentScreenName', 'Text']\n",
    "tweet_dfs = []\n",
    "for i in range(num_root_tweets):\n",
    "    tweet_df = pd.read_csv(path+root_tweet_names[i], sep=\"\\t\", header=None, \n",
    "                         quoting=csv.QUOTE_NONE, names=fields, encoding = \"ISO-8859-1\")\n",
    "    \n",
    "    tweet_df['Time'] = pd.to_datetime(tweet_df['Time'])\n",
    "\n",
    "    screen_name_index = {}\n",
    "    for index, row in tweet_df.iterrows():\n",
    "        screen_name_index[row['ScreenName']] = index\n",
    "    tweet_df['ParentDfIndex'] = tweet_df['ParentScreenName'].map(screen_name_index)\n",
    "    tweet_df.fillna(0)\n",
    "    tweet_dfs.append(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dictionary of reaction times S_j^x keyed by user id\n",
    "def generate_reaction_times(tweet_df):\n",
    "    reaction_times = {}\n",
    "    for index, row in tweet_df.iterrows():\n",
    "        if index > 0:\n",
    "            reaction_time = row['Time'] - tweet_df.at[row['ParentDfIndex'],\n",
    "                                                      'Time']\n",
    "            reaction_times[row['UserId']] = reaction_time\n",
    "    return reaction_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dictionary of M_j^x keyed by user id\n",
    "def generate_number_of_follower_who_retweet(tweet_df):\n",
    "    number_of_follower_who_retweet = {}\n",
    "    for index, row in tweet_df.iterrows():\n",
    "        if row['UserId'] not in number_of_follower_who_retweet:\n",
    "            number_of_follower_who_retweet[row['UserId']] = 0\n",
    "        parent_user_id = tweet_df.at[row['ParentDfIndex'], 'UserId']\n",
    "        number_of_follower_who_retweet[parent_user_id] += 1\n",
    "    return number_of_follower_who_retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph_info(tweet_df, rt_dic):\n",
    "    depth = []\n",
    "    num_followers = []\n",
    "    num_retweets = []\n",
    "    for index, row in tweet_df.iterrows():\n",
    "        if row['UserId'] != 'None':\n",
    "            depth.append(row['DistanceFromRoot'])\n",
    "            if row['FollowerCount'] == 'None':\n",
    "                num_followers.append(0)\n",
    "            else:\n",
    "                num_followers.append(int(row['FollowerCount']))\n",
    "            if row['UserId'] in rt_dic:\n",
    "                num_retweets.append(rt_dic[row['UserId']])\n",
    "            else:\n",
    "                num_reweets.append(0)\n",
    "    return depth, num_followers, num_retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_s_j_x = []\n",
    "# These three are parallel arrays for each retweet \n",
    "# (depth[i], num_followers[i], num_retweets[i] all refer to the same retweet)\n",
    "depth = []\n",
    "num_followers = []\n",
    "num_retweets = []\n",
    "for i in range(len(root_tweet_names)):\n",
    "    s_j_x = sorted(generate_reaction_times(tweet_dfs[i]).values())\n",
    "    log_s_j_x.append([np.log(i.seconds) for i in s_j_x])\n",
    "    M_j_dic = generate_number_of_follower_who_retweet(tweet_dfs[i])\n",
    "    d_x, M_j_x, m_j_x = generate_graph_info(tweet_dfs[i], M_j_dic)\n",
    "    depth.extend(d_x)\n",
    "    num_followers.extend(M_j_x)\n",
    "    num_retweets.extend(m_j_x)\n",
    "depth = np.array(depth)\n",
    "num_followers = np.array(num_followers)\n",
    "num_retweets = np.array(num_retweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_likelihood(S_x, m_x, a_x, t_x, M, m_t, t, T):\n",
    "    nCr = lambda x,y: math.factorial(x) / (math.factorial(y) * math.factorial(x - y))\n",
    "    choose_func = theano.function([a,b] nCr(a,b))\n",
    "    choose_term = tt.prod(choose_func(M, m_t))\n",
    "    \n",
    "    gauss = scipy.stats.norm(a_x, t_x)\n",
    "    F = lambda x: gauss.cdf(x)\n",
    "    f_func = theano.function([a,b], lambda x,y: (1 - F(x))**y)\n",
    "    f_term = tt.prod(f_func(tt.log(t - T), M - m_t))\n",
    "    \n",
    "    \n",
    "    rxn_term = tt.prod(gauss.pdf(S_x))\n",
    "    \n",
    "    return rxn_term * f_term * choose_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pymc3 model \n",
    "with pm.Model() as time_model:\n",
    "    # global model parameters\n",
    "    # Time-related hyperparameters\n",
    "    alpha = pm.Normal('alpha', mu=0, sd=100)\n",
    "    sigma_squared_delta = pm.InverseGamma('sigma_squared_delta', alpha=2, beta=2)\n",
    "    log_a_tau = pm.Normal('log_a_tau', mu=0, sd=10)\n",
    "    b_tau = pm.Gamma('b_tau', alpha=1, beta=.002)\n",
    "    \n",
    "    # log-normal model for reaction times, nonrecursive...\n",
    "    a_tau = pm.Deterministic('a_tau', pm.math.exp(log_a_tau))\n",
    "    for i in range(num_root_tweets):\n",
    "        t_x = pm.InverseGamma('tau_x_squared_' + str(i), alpha=a_tau, beta=b_tau)\n",
    "        a_x = pm.Normal('alpha_x_' + str(i), mu=alpha, tau=1/sigma_squared_delta)        \n",
    "        l_x = pm.Normal('log_s_j_x_' + str(i), mu=a_x, sd=t_x**0.5, observed=log_s_j_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as graph_model:\n",
    "    # Graph-related hyperparameters\n",
    "    sigma_squared_b = pm.InverseGamma('sigma_squared_b', alpha=0.5, beta=0.5, testval=10000)\n",
    "    beta_0 = pm.Normal('beta_0', mu=0, tau=1/10000, testval=1.99)\n",
    "    beta_F = pm.Normal('beta_F', mu=0, tau=1/10000, testval=-0.79)\n",
    "    beta_d = pm.Normal('beta_d', mu=0, tau=1/10000)\n",
    "    \n",
    "    u_j = beta_0 + beta_F * pm.math.log(num_followers+1) + beta_d * pm.math.log(depth+1)\n",
    "    logit_b_j = pm.Normal('logit_b_j', mu=u_j, tau=1/sigma_squared_b, shape=len(depth))\n",
    "    b_j = pm.math.invlogit(logit_b_j)\n",
    "    M_j = pm.Binomial('retweet_count M_j', n=num_followers, p=b_j, observed=num_retweets)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and fit our model\n",
    "with time_model:\n",
    "    trace = pm.sample(1000, tune=2000, cores=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and fit our model\n",
    "with graph_model:\n",
    "    trace = pm.sample(1000, tune=1000, cores=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph all of the important distributions\n",
    "with time_model:\n",
    "    imp_dists = ['alpha', 'sigma_squared_delta', 'a_tau', 'b_tau']\n",
    "    fig, axs = plt.subplots(2,2, figsize = (8,8))\n",
    "    for i in range(len(imp_dists)):\n",
    "        ax1 = axs[int(i/2)][i%2]\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.set(ylim=(-.25, .25))\n",
    "        var = imp_dists[i]\n",
    "        sns.distplot(trace[var], ax=ax1).set_title(var);\n",
    "        sns.boxplot(trace[var], ax=ax2, notch=True)\n",
    "        print(var + \": \" + str(np.mean(trace[var])) + \"(\" + str(np.std(trace[var])) + \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph_model:\n",
    "    pm.traceplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph_model:\n",
    "    imp_dists = ['sigma_squared_b', 'beta_0', 'beta_F', 'beta_d']\n",
    "#    fig, axs = plt.subplots(2,2, figsize = (8,8))\n",
    "    for i in range(len(imp_dists)):\n",
    "#         ax1 = axs[int(i/2)][i%2]\n",
    "#         ax2 = ax1.twinx()\n",
    "#         ax2.set(ylim=(-.25, .25))\n",
    "         var = imp_dists[i]\n",
    "#         sns.distplot(trace[var], ax=ax1).set_title(var);\n",
    "#         sns.boxplot(trace[var], ax=ax2, notch=True)\n",
    "        print(var + \": \" + str(np.mean(trace[var])) + \"(\" + str(np.std(trace[var])) + \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
