{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import itertools\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import xlrd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '../RetweetDataAOAS/retweet_data/'\n",
    "root_tweet_names = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "# Produces a dictionary of dataframes for each tweetfile, with initial \n",
    "# preprocessing\n",
    "fields = ['RetweetCount', 'UserId', 'ScreenName', 'FollowerCount', \n",
    "          'DistanceFromRoot','Time', 'ParentScreenName', 'Text']\n",
    "tweet_dfs = {}\n",
    "for i in range(len(root_tweet_names)):\n",
    "    tweet_df = pd.read_csv(path+root_tweet_names[i], sep=\"\\t\", header=None, \n",
    "                         quoting=csv.QUOTE_NONE, names=fields, encoding = \"ISO-8859-1\")\n",
    "    \n",
    "    tweet_df['Time'] = pd.to_datetime(tweet_df['Time'])\n",
    "\n",
    "    screen_name_index = {}\n",
    "    for index, row in tweet_df.iterrows():\n",
    "        screen_name_index[row['ScreenName']] = index\n",
    "    tweet_df['ParentDfIndex'] = tweet_df['ParentScreenName'].map(screen_name_index)\n",
    "    tweet_df[['FollowerCount','UserId']] = tweet_df[['FollowerCount','UserId']].apply(pd.to_numeric, errors='coerce')\n",
    "    tweet_df[['FollowerCount','UserId']] = tweet_df[['FollowerCount','UserId']].fillna(0)\n",
    "    tweet_dfs[i] = tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source_followers_tweet_0137_Therealkiss.txt\n",
      "Source_followers_tweet_0108_newtgingrich.txt\n",
      "Source_followers_tweet_0533_BarackObama.txt\n",
      "Source_followers_tweet_0349_KimKardashian.txt\n",
      "Source_followers_tweet_0785_KimKardashian.txt\n",
      "Source_followers_tweet_0069_bobatl.txt\n",
      "Source_followers_tweet_0101_myfabolouslife.txt\n",
      "Source_followers_tweet_0024_pbsgwen.txt\n",
      "Source_followers_tweet_0176_AnnCoulter.txt\n",
      "Source_followers_tweet_1134_JLin7.txt\n",
      "Source_followers_tweet_0608_rickyrozay.txt\n",
      "Source_followers_tweet_0294_myfabolouslife.txt\n",
      "Source_followers_tweet_0462_AnnDRomney.txt\n",
      "Source_followers_tweet_0506_billmaher.txt\n",
      "Source_followers_tweet_0611_BarackObama.txt\n",
      "Source_followers_tweet_0189_sethmeyers21.txt\n",
      "Source_followers_tweet_0167_rickyrozay.txt\n",
      "Source_followers_tweet_0031_CNET.txt\n",
      "Source_followers_tweet_0044_JonnyBones.txt\n",
      "Source_followers_tweet_0127_hilaryr.txt\n",
      "Source_followers_tweet_0068_CharlesMBlow.txt\n",
      "Source_followers_tweet_0026_realMickFoley.txt\n",
      "Source_followers_tweet_0127_newtgingrich.txt\n",
      "Source_followers_tweet_060_IAmJericho.txt\n",
      "Source_followers_tweet_0070_E40.txt\n",
      "Source_followers_tweet_0037_EvaLongoria.txt\n",
      "Source_followers_tweet_0101_GarryShandling.txt\n",
      "Source_followers_tweet_0212_jasonsegel.txt\n",
      "Source_followers_tweet_0256_OFA.txt\n",
      "Source_followers_tweet_0074_Tip.txt\n",
      "Source_followers_tweet_0734_rickyrozay.txt\n",
      "Source_followers_tweet_0142_myfabolouslife.txt\n",
      "Source_followers_tweet_0028_AnnCoulter.txt\n",
      "Source_followers_tweet_0306_foxnewsalert.txt\n",
      "Source_followers_tweet_0370_EvaLongoria.txt\n",
      "Source_followers_tweet_0091_CharlesMBlow.txt\n",
      "Source_followers_tweet_0022_Lawrence.txt\n",
      "Source_followers_tweet_0085_MrChuckD.txt\n",
      "Source_followers_tweet_0101_Pitbull.txt\n",
      "Source_followers_tweet_0161_SuckerFreeMTV2.txt\n",
      "Source_followers_tweet_0048_MissInfoTV.txt\n",
      "Source_followers_tweet_1267_TheRock.txt\n",
      "Source_followers_tweet_0165_GG.txt\n",
      "Source_followers_tweet_0107_djkhaled.txt\n",
      "Source_followers_tweet_0203_BarackObama.txt\n",
      "Source_followers_tweet_0092_jasonsegel.txt\n",
      "Source_followers_tweet_0092_AnnCoulter.txt\n",
      "Source_followers_tweet_0118_iamdiddy.txt\n",
      "Source_followers_tweet_0271_hilaryr.txt\n",
      "Source_followers_tweet_0304_KimKardashian.txt\n",
      "Source_followers_tweet_0031_ASAPYams.txt\n",
      "Source_followers_tweet_0074_iamwill.txt\n"
     ]
    }
   ],
   "source": [
    "tweet_name_to_index = {}\n",
    "for i in range(len(root_tweet_names)):\n",
    "    tweet_name_to_index[root_tweet_names[i]] = i\n",
    "for key in tweet_name_to_index.keys():\n",
    "    print key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u'Source_followers_tweet_0068_bobatl.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-c76ef463543e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprediction_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_partition_file_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpartitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet_name_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_file_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpartitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet_name_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction_file_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u'Source_followers_tweet_0068_bobatl.txt'"
     ]
    }
   ],
   "source": [
    "def format_partition_file_name(name):\n",
    "    root = name.split('.')\n",
    "    items = root[0].split('_')\n",
    "    items[-2], items[-1] = items[-1], items[-2]\n",
    "    return \".\".join([\"_\".join(items), root[-1]])\n",
    "\n",
    "path = '../RetweetDataAOAS/Partition/'\n",
    "partition_names = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "partitions = {}\n",
    "# for i in range(len(partition_names)):\n",
    "for i in range(2, 3):\n",
    "    partitions[i] = {}\n",
    "    partition_df = pd.read_excel(path+partition_names[i], encoding = \"ISO-8859-1\")\n",
    "    for index, row in partition_df.iterrows():\n",
    "        training_file_name = format_partition_file_name(row['Training'])\n",
    "        prediction_file_name = format_partition_file_name(row['Prediction'])\n",
    "        partitions[i][tweet_name_to_index[training_file_name]] = True\n",
    "        partitions[i][tweet_name_to_index[prediction_file_name]] = False\n",
    "    print partitions[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns a dictionary of reaction times S_j^x keyed by user id\n",
    "def generate_reaction_times(tweet_df):\n",
    "    reaction_times = []\n",
    "    for index, row in tweet_df.iterrows():\n",
    "        if index > 0:\n",
    "            reaction_time = row['Time'] - tweet_df.at[row['ParentDfIndex'],\n",
    "                                                      'Time']\n",
    "            reaction_times.append(reaction_time)\n",
    "    return reaction_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns a dictionary of M_j^x keyed by user id\n",
    "def generate_number_of_follower_who_retweet(tweet_df):\n",
    "    number_of_follower_who_retweet = {}\n",
    "    for index, row in tweet_df.iterrows():\n",
    "        if row['UserId'] not in number_of_follower_who_retweet:\n",
    "            number_of_follower_who_retweet[row['UserId']] = 0\n",
    "        parent_user_id = tweet_df.at[row['ParentDfIndex'], 'UserId']\n",
    "        number_of_follower_who_retweet[parent_user_id] += 1\n",
    "    return number_of_follower_who_retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_df_1 = tweet_dfs[1]\n",
    "s_j_x = sorted(generate_reaction_times(tweet_df_1).values())\n",
    "log_s_j_x = [np.log(i.seconds) for i in s_j_x]\n",
    "tweet_df_1_users = list(tweet_df_1['UserId'])\n",
    "m_j_x_dic = generate_number_of_follower_who_retweet(tweet_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def f(x, y):\n",
    "    return x*y\n",
    "def multiply(elements):\n",
    "    return reduce(f, elements)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scratch pymc3 code\n",
    "with pm.Model() as tweet_model:\n",
    "    # global model parameters\n",
    "    alpha = pm.Normal('alpha', mu=0, sd=100)\n",
    "    sigma_squared_delta = pm.InverseGamma('sigma_squared_delta', alpha=2, beta=2)\n",
    "    log_a_tau = pm.Normal('log_a_tau', mu=0, sd=10)\n",
    "    b_tau = pm.Gamma('b_tau', alpha=1, beta=0.002)\n",
    "#     beta_0 = pm.Normal('beta_0', mu=0, sd=100)\n",
    "#     beta_f = pm.Normal('beta_f', mu=0, sd=100)\n",
    "#     beta_d = pm.Normal('beta_d', mu=0, sd=100)\n",
    "#     sigma_squared_b = pm.InverseGamma('sigma_squared_b', alpha=0.5, beta=0.5)\n",
    "    a_tau = pm.math.exp(log_a_tau)\n",
    "    \n",
    "    # tweet specific parameters, keyed by tweet x\n",
    "    tau_squared_dic = {}\n",
    "    alpha_dic = {}\n",
    "    log_s_probability_dic = {}\n",
    "    m_probability_dic = {}\n",
    "    logit_b_dic = {}\n",
    "    likelihood_training_tweets = {}\n",
    "    likelihood_prediction_tweets = {}\n",
    "    \n",
    "    num_root_tweets = len(tweet_dfs)\n",
    "    num_root_tweets = 2\n",
    "    for x in range(num_root_tweets):\n",
    "        tweet_df = tweet_dfs[x]\n",
    "        s = generate_reaction_times(tweet_df)\n",
    "        log_s = [np.log(i.seconds) for i in s]        \n",
    "        tweet_df_users = list(tweet_df['UserId'])\n",
    "        m_dic = generate_number_of_follower_who_retweet(tweet_df)\n",
    "\n",
    "        # log-normal model for reaction times\n",
    "        tau_squared_dic[x] = pm.InverseGamma('tau_{}_squared'.format(x), alpha=a_tau, beta=b_tau)\n",
    "        alpha_dic[x] = pm.Normal('alpha_{}'.format(x), mu=alpha, tau=1/sigma_squared_delta)\n",
    "        \n",
    "        log_s_probability_dic[x] = {}\n",
    "        for j in range(1, len(tweet_df_users)):\n",
    "            log_s_probability_dic[x][j] = pm.Normal('log_s_{}_{}'.format(x,j), mu=alpha_dic[x],\n",
    "                                                tau=1/tau_squared_dic[x], observed=log_s[j-1])\n",
    "        \n",
    "        # binomial model for retweet graph structure\n",
    "        logit_b_dic[x] = {}\n",
    "        m_probability_dic[x] = {}        \n",
    "        for j, row in tweet_df.iterrows():\n",
    "            user = tweet_df_users[j]\n",
    "            f_j_x = int(row['FollowerCount'])\n",
    "            d_j_x = row['DistanceFromRoot']\n",
    "            mu_j_x = pm.Deterministic('mu_{}_{}'.format(x,j), beta_0 + beta_f * np.log(f_j_x + 1) + beta_d * np.log(d_j_x + 1))\n",
    "            logit_b_dic[x][j] = pm.Normal('logit_b_{}_{}'.format(x,j), mu=mu_j_x, tau=1/sigma_squared_b)            \n",
    "            b_j_x = pm.Deterministic('b_{}_{}'.format(x,j), pm.math.x(logit_b_dic[x][j]))\n",
    "            m_probability_dic[x][j] = pm.Binomial('m_{}_{}'.format(x, j), n=f_j_x, p=b_j_x,\n",
    "                                             observed=m_dic[user])\n",
    "        \n",
    "        # TODO - use partitions to check if a tweet is used for training or prediction\n",
    "        # if training\n",
    "        likelihood_training_tweets[x] = m_probability_dic[x][0]\n",
    "        for j in range(1, len(tweet_df_users)):\n",
    "            likelihood_training_tweets[x] = likelihood_training_tweets[x] * log_s_probability_dic[x][\n",
    "                                            j] * m_probability_dic[x][j]        \n",
    "        if prediction\n",
    "    def f(x, y):\n",
    "        return x*y\n",
    "    def multiply(elements):\n",
    "        return reduce(f, elements)\n",
    "    \n",
    "    phi = [alpha, sigma_squared_delta, log_a_tau, b_tau, beta_0, beta_f, beta_d, sigma_squared_b]\n",
    "    p_phi = pm.Deterministic('p_phi', multiply(phi))\n",
    "    # multiplying along x\n",
    "    p_alpha = pm.Deterministic('p_alpha', reduce(f, alpha_dic.values()))\n",
    "    # multiplying along x\n",
    "    p_tau = pm.Deterministic('p_tau', reduce(f, tau_squared_dic.values()))\n",
    "    # multiplying along x,j\n",
    "    m_to_collapse = [m_x.values() for m_x in m_probability_dic.values()]\n",
    "    collapsed_m = list(itertools.chain(*m_to_collapse))\n",
    "    p_m = pm.Deterministic('p_m', reduce(f, collapsed_m))\n",
    "    # multiplying along x,j\n",
    "    b_to_collapse = [b_x.values() for b_x in logit_b_dic.values()]\n",
    "    collapsed_b = list(itertools.chain(*b_to_collapse))\n",
    "    p_b = pm.Deterministic('p_b', reduce(f, collapsed_b))\n",
    "    # multiplying along trained tweets (currently x)\n",
    "    p_train_tweets = pm.Deterministic('p_train_tweets', reduce(f, likelihood_training_tweets.values()))\n",
    "    # multiplying along prediction tweets (currently x)\n",
    "    # not implemented yet\n",
    "    p_prediction_tweets = pm.Deterministic('p_prediction_tweets', reduce(lambda x, y: x*y, likelihood_prediction_tweets.values()))\n",
    "    p_list = [p_phi, p_alpha, p_tau, p_m, p_b, p_train_tweets, p_prediction_tweets]\n",
    "    posterior = pm.Deterministic('posterior', reduce(lam))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tweet_model:\n",
    "    trace = pm.sample(1000, tune=2000, cores=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
