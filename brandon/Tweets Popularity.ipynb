{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "path = '../RetweetDataAOAS/retweet_data/'\n",
    "root_tweet_names = [f for f in listdir(path) if isfile(join(path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Produces a dictionary of dataframes for each tweetfile, with initial \n",
    "# preprocessing\n",
    "fields = ['RetweetCount', 'UserId', 'ScreenName', 'FollowerCount', \n",
    "          'DistanceFromRoot','Time', 'ParentScreenName', 'Text']\n",
    "tweet_dfs = {}\n",
    "for i in range(len(root_tweet_names)):\n",
    "    tweet_df = pd.read_csv(path+root_tweet_names[i], sep=\"\\t\", header=None, \n",
    "                         quoting=csv.QUOTE_NONE, names=fields)\n",
    "    \n",
    "    tweet_df['Time'] = pd.to_datetime(tweet_df['Time'])\n",
    "\n",
    "    screen_name_index = {}\n",
    "    for index, row in tweet_df.iterrows():\n",
    "        screen_name_index[row['ScreenName']] = index\n",
    "    tweet_df['ParentDfIndex'] = tweet_df['ParentScreenName'].map(screen_name_index)\n",
    "    \n",
    "    tweet_dfs[i] = tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Returns a dictionary of reaction times S_j^x keyed by user id\n",
    "def generate_reaction_times(tweet_df):\n",
    "    reaction_times = {}\n",
    "    for index, row in tweet_df.iterrows():\n",
    "        if index > 0:\n",
    "            reaction_time = row['Time'] - tweet_df.at[row['ParentDfIndex'],\n",
    "                                                      'Time']\n",
    "            reaction_times[row['UserId']] = reaction_time\n",
    "    return reaction_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Returns a dictionary of M_j^x keyed by user id\n",
    "def generate_number_of_follower_who_retweet(tweet_df):\n",
    "    number_of_follower_who_retweet = {}\n",
    "    for index, row in tweet_df.iterrows():\n",
    "        if row['UserId'] not in number_of_follower_who_retweet:\n",
    "            number_of_follower_who_retweet[row['UserId']] = 0\n",
    "        parent_user_id = tweet_df.at[row['ParentDfIndex'], 'UserId']\n",
    "        number_of_follower_who_retweet[parent_user_id] += 1\n",
    "    return number_of_follower_who_retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_df_1 = tweet_dfs[1]\n",
    "s_j_x = sorted(generate_reaction_times(tweet_df_1).values())\n",
    "log_s_j_x = [np.log(i.seconds) for i in s_j_x]\n",
    "tweet_df_1_users = list(tweet_df_1['UserId'])\n",
    "m_j_x_dic = generate_number_of_follower_who_retweet(tweet_df_1)\n",
    "m_j_x_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def f(x, y):\n",
    "    return x*y\n",
    "def multiply(elements):\n",
    "    return reduce(f, elements)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scratch pymc3 code\n",
    "with pm.Model() as hierarchical:\n",
    "    # global model parameters\n",
    "    alpha = pm.Normal('alpha', mu=0, sd=100)\n",
    "    sigma_squared_delta = pm.InverseGamma('sigma_squared_delta', alpha=0.5, beta=0.5)\n",
    "    log_a_tau = pm.Normal('log_a_tau', mu=0, sd=10)\n",
    "    b_tau = pm.Gamma('b_tau', alpha=1, beta=0.002)\n",
    "    beta_0 = pm.Normal('beta_0', mu=0, sd=100)\n",
    "    beta_f = pm.Normal('beta_f', mu=0, sd=100)\n",
    "    beta_d = pm.Normal('beta_d', mu=0, sd=100)\n",
    "    sigma_squared_b = pm.InverseGamma('sigma_squared_b', alpha=0.5, beta=0.5)\n",
    "    a_tau = pm.math.exp(log_a_tau)\n",
    "    \n",
    "    # tweet specific parameters, keyed by tweet x\n",
    "    tau_squared = {}\n",
    "    alpha = {}\n",
    "    log_s_probability = {}\n",
    "    m_probability = {}\n",
    "    logit_b = {}\n",
    "    likelihood_training_tweets = {}\n",
    "    likelihood_prediction_tweets = {}\n",
    "    \n",
    "    for x in range(len(tweet_dfs)):\n",
    "        tweet_df = tweet_dfs[x]\n",
    "        s = sorted(generate_reaction_times(tweet_df).values())\n",
    "        log_s = [np.log(i.seconds) for i in s_j_x]        \n",
    "        tweet_df_users = list(tweet_df['UserId'])\n",
    "        m_dic = generate_number_of_follower_who_retweet(tweet_df)\n",
    "\n",
    "        # log-normal model for reaction times\n",
    "        tau_squared[x] = pm.InverseGamma('tau_{}_squared'.format(x), alpha=a_tau, beta=b_tau)\n",
    "        alpha[x] = pm.Normal('alpha_{}'.format(x), alpha=alpha, tau=1/sigma_squared_delta)\n",
    "        \n",
    "        log_s_probability[x] = {}\n",
    "        for j in range(1, len(tweet_df_users)):\n",
    "            log_s_probability[x][j] = pm.Normal('log_s_{}_{}'.format(x,j), mu=alpha[x],\n",
    "                                                tau=1/tau_squared[x], observed=log_s[j])\n",
    "        \n",
    "        # binomial model for retweet graph structure\n",
    "        m_probability[x] = {}\n",
    "        for j in range(len(tweet_df_users)):\n",
    "            user = tweet_df_users[j]\n",
    "            f_j_x = tweet_df.loc[tweet_df['UserId'] == user]['FollowerCount']\n",
    "            d_j_x = tweet_df.loc[tweet_df['UserId'] == user]['DistanceFromRoot']\n",
    "            mu_j_x = beta_0 + beta_F * np.log(f_j_x + 1) + beta_d * np.log(d_j_x + 1)\n",
    "            logit_b[x][j] = pm.Normal('logit_b_{}_{}'.format(x,j), mu=mu_j_x, tau=1/sigma_squared_b)\n",
    "            b_j_x = pm.Deterministic('b_{}_{}'.format(x,j), pm.math.invlogit(logit_b[x][j]))\n",
    "            m_probability[x][j] = pm.Binomial('m_{}_{}'.format(x, j), n=f_j_x, p=b_j_x,\n",
    "                                             observed=m_dic[user])\n",
    "        # TODO - use partitions to check if a tweet is used for training or prediction\n",
    "        # if training\n",
    "        likelihood_training_tweets[x] = m_probability[0]\n",
    "        for j in range(1, len(tweet_df_users)):\n",
    "            likelihood_training_tweets[x] = likelihood_training_tweets[x] * log_s_probability[x][\n",
    "                                            j] * m_probability[x][j]        \n",
    "        # if prediction\n",
    "    def f(x, y):\n",
    "        return x*y\n",
    "    def multiply(elements):\n",
    "        return reduce(f, elements)\n",
    "    \n",
    "    phi = [alpha, sigma_squared_delta, log_a_tau, b_tau, beta_0, beta_F, beta_d, beta_f, beta_d, sigma_squared_b]\n",
    "    p_phi = pm.Deterministic('p_phi', multiply(phi))\n",
    "    # multiplying along x\n",
    "    p_alpha = pm.Deterministic('p_alpha', reduce(f, alpha.values()))\n",
    "    # multiplying along x\n",
    "    p_tau = pm.Deterministic('p_tau', reduce(f, tau_squared.values()))\n",
    "    # multiplying along x,j\n",
    "    m_to_collapse = [m_x.values() for m_x in m_probability.values()]\n",
    "    collapsed_m = list(itertools.chain(*m_to_collapse))\n",
    "    p_m = pm.Deterministic('p_m', reduce(f, collapsed_m))\n",
    "    # multiplying along x,j\n",
    "    b_to_collapse = [b_x.values() for b_x in logit_b.values()]\n",
    "    collapsed_b = list(itertools.chain(*b_to_collapse))\n",
    "    p_b = pm.Deterministic('p_b', reduce(f, collapsed_b))\n",
    "    # multiplying along trained tweets (currently x)\n",
    "    p_train_tweets = pm.Deterministic('p_train_tweets', reduce(f, likelihood_training_tweets.values()))\n",
    "    # multiplying along prediction tweets (currently x)\n",
    "    # not implemented yet\n",
    "    p_prediction_tweets = pm.Deterministic('p_prediction_tweets', reduce(lambda x, y: x*y, likelihood_prediction_tweets.values()))\n",
    "    p_list = [p_phi, p_alpha, p_tau, p_m, p_b, p_train_tweets, p_prediction_tweets]\n",
    "    posterior = pm.Deterministic('posterior', reduce(lam))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
